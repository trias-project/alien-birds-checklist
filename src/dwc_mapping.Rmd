---
title: "Darwin Core mapping"
subtitle: "For: Checklist of Alien Birds of Belgium"
author:
- Cristina Preda
- Tim Adriaens
- Peter Desmet
- Lien Reyserhove
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
#  pdf_document:
#    df_print: kable
#    number_sections: yes
#    toc: yes
#    toc_depth: 3
---

# Setup 

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Load libraries:

```{r}
library(tidyverse)      # To do data science
library(magrittr)       # To use %<>% pipes
library(here)           # To find files
library(digest)         # To generate hashes
library(rgbif)          # To use GBIF services
library(googlesheets)   # To import and read Google spreadsheets 
```

# Read source data

Retrieve the [checklist of alien birds Belgium ](https://docs.google.com/spreadsheets/d/1ugsmAq_tlUjFmZef2zyw-mT0Tq1jSdPlNO4KTfJyXVo/edit#gid=0) which is a google spreadheet:

```{r connect_google_spreadsheets}
retrieve_spreadsheet <- gs_title("Checklist of alien birds Belgium")
```

Select the data in the worksheet `checklist`:

```{r read_source_data}
input_data <- retrieve_spreadsheet %>% gs_read("checklist") # Also trims values
```

We want to add a copy of the source data to the repository:

```{r}
write_csv(input_data, here("data", "raw", "alien_bird_checklist_dump.csv"), na = "")
```

Preview data: 

```{r}
input_data %>% head()
```

# Process source data

## Tidy data

Clean names:

```{r}
input_data %<>% clean_names()
```

## Scientific names

Use the [GBIF nameparser](https://www.gbif.org/tools/name-parser) to retrieve nomenclatural information for the scientific names in the checklist:

```{r}
parsed_names <- input_data %>%
  distinct(scientific_name) %>%
  pull() %>% # Create vector from dataframe
  parsenames() # An rgbif function
```

Show scientific names with nomenclatural issues, i.e. not of `type = SCIENTIFIC` or that could not be fully parsed. Note: these are not necessarily incorrect.

```{r}
parsed_names %>%
  select(scientificname, type, parsed, parsedpartially, rankmarker) %>%
  filter(!(type == "SCIENTIFIC" & parsed == "TRUE" & parsedpartially == "FALSE"))
```

There are no nomenclatural issues here, so there's no need for cleaning of the scientific names.

## Taxon IDs

To link taxa with information in the extension(s), each taxon needs a unique and relatively stable `taxonID`. Here we create one in the form of `dataset_shortname:taxon:hash`, where `hash` is unique code based on scientific name and kingdom (that will remain the same as long as scientific name and kingdom remain the same):

```{r}
vdigest <- Vectorize(digest) # Vectorize digest function to work with vectors
input_data %<>% mutate(taxon_id = paste(
  "alien-birds-checklist", # e.g. "alien-fishes-checklist"
  "taxon",
  vdigest(paste(scientific_name, kingdom), algo = "md5"),
  sep = ":"
))
```

## Preview data

Show the number of taxa and distributions per kingdom and rank:

```{r}
input_data %>%
  group_by(kingdom, taxon_rank) %>%
  summarize(
    `# taxa` = n_distinct(taxon_id),
    `# distributions` = n()
  ) %>%
  adorn_totals("row")
```

Preview data:

```{r}
input_data %>% head()
```

# Taxon core

## Pre-processing

Create a dataframe with unique taxa only (ignoring potential multiple distribution rows):

```{r}
taxon <- input_data %>% distinct(taxon_id, .keep_all = TRUE)
```

## Term mapping

Map the data to [Darwin Core Taxon](http://rs.gbif.org/core/dwc_taxon_2015-04-24.xml).

Start with record-level terms which contain metadata about the dataset (which is generally the same for all records).

### language

```{r}
taxon %<>% mutate(dwc_language = "en")
```

### license

```{r}
taxon %<>% mutate(dwc_license = "http://creativecommons.org/publicdomain/zero/1.0/")
```

### rightsHolder

```{r}
taxon %<>% mutate(dwc_rightsHolder = "INBO")
```

### datasetID

```{r}
taxon %<>% mutate(dwc_datasetID = "")
```

### institutionCode

```{r}
taxon %<>% mutate(dwc_institutionCode = "INBO")
```

### datasetName

```{r}
taxon %<>% mutate(dwc_datasetName = "Checklist of alien birds of Belgium") 
```

The following terms contain information about the taxon:

### taxonID

```{r}
taxon %<>% mutate(dwc_taxonID = taxon_id)
```

### scientificName

```{r}
taxon %<>% mutate(dwc_scientificName = scientific_name)
```

### kingdom

Inspect values:

```{r}
taxon %>%
  group_by(kingdom) %>%
  count()
```

Map values:

```{r}
taxon %<>% mutate(dwc_kingdom = kingdom)
```

### taxonRank

Inspect values:

```{r}
taxon %>%
  group_by(taxon_rank) %>%
  count()
```

Map values by recoding to the [GBIF rank vocabulary](http://rs.gbif.org/vocabulary/gbif/rank_2015-04-24.xml):

```{r}
taxon %<>% mutate(dwc_taxonRank = taxon_rank)
```

### nomenclaturalCode

```{r}
taxon %<>% mutate(dwc_nomenclaturalCode = "ICZN")
```

## Post-processing

Only keep the Darwin Core columns:

```{r}
taxon %<>% select(starts_with("dwc_"))
```

Drop the `dwc_` prefix:

```{r}
colnames(taxon) <- str_replace(colnames(taxon), "dwc_", "")
```

Preview data:

```{r}
taxon %>% head()
```

Save to CSV:

```{r}
write_csv(taxon, here("data", "processed", "taxon.csv"), na = "")
```

# Distribution extension

## Pre-processing

Create a dataframe with all data:

```{r}
distribution <- input_data
```

## Term mapping

Map the data to [Species Distribution](http://rs.gbif.org/extension/gbif/1.0/distribution.xml).

### taxonID

```{r}
distribution %<>% mutate(dwc_taxonID = taxon_id)
```

### locality

Inspect values:

```{r}
distribution %>%
  group_by(country_code, location) %>%
  count()
```

Set current NA's in `location` to `Belgium`:

```{r}
distribution %<>% mutate(location_be = case_when(
  is.na(location) ~ "Belgium",
  TRUE ~ location
))
```

Separate values in `location_be`

```{r}
distribution %<>% separate(col = location_be, 
                          into = c("location_1", "location_2"),
                          remove = FALSE,
                          sep = ", ")
```

Inspect data:

```{r}
distribution %>% head()
```

Change from wide to long dataset:

```{r}
distribution %<>% gather(key = "key",
                        value = "dwc_locality",
                        location_1, location_2,
                        na.rm = TRUE)
```

Inspect mapped values: 

```{r}
distribution %>%
  group_by(country_code, location, dwc_locality) %>%
  count()
```

### locationID

Map `locationID` to [ISO 3166 code]

```{r}
distribution %<>% mutate(dwc_locationID = case_when(
  dwc_locality == "Belgium" ~ "ISO_3166-2:BE",
  dwc_locality == "Flanders" ~ "ISO_3166-2:BE-VLG",
  dwc_locality == "Wallonia" ~ "ISO_3166-2:BE-WAL",
  dwc_locality == "Brussels" ~ "ISO_3166-2:BE-BRU"))
```

Inspect values:

```{r}
distribution %>%
  group_by(dwc_locality, dwc_locationID) %>%
  count()
```

### countryCode

Inspect values:

```{r}
distribution %>%
  group_by(country_code) %>%
  count()
```

Map values:

```{r}
distribution %<>% mutate(dwc_countryCode = country_code) 
```

### occurrenceStatus

Inspect values:

```{r}
distribution %>%
  group_by(occurrence_status) %>%
  count()
```

Map values:

```{r}
distribution %<>% mutate(dwc_occurrenceStatus = occurrence_status) 
```

### establishmentMeans

```{r}
distribution %<>% mutate(dwc_establishmentMeans = "introduced")
```

### eventDate

Inspact values for `date_first_observation`:

```{r}
distribution %>%
  group_by(date_first_observation) %>%
  count()
```

All date information should comply to the ISO 8601 standard, which requires a four-digit year as a minimum.
We here transform deviating values:

```{r}
distribution %<>% mutate(
  date_first_observation = recode(
    .x = date_first_observation,
    "18th century" = "1701",
    "1890s" = "1890",
    "1950ies" = "1950"
))
```

Inspact values for `date_last_observation`:

```{r}
distribution %>%
  group_by(date_last_observation) %>%
  count()
```

Inspect all combinations of `date_first_observation` and `date_last_observation`:

```{r}
distribution %>%
  group_by(date_first_observation, date_last_observation) %>%
  count()
```

Map `eventDate`:

```{r}
distribution %<>% mutate(
  dwc_eventDate = case_when(
    is.na(date_first_observation) & is.na(date_last_observation) ~ NA_character_,
    is.na(date_first_observation) & !is.na(date_last_observation) ~ date_last_observation,
    !is.na(date_first_observation) & is.na(date_last_observation) ~ date_first_observation,
    !is.na(date_first_observation) & !is.na(date_last_observation) ~ paste(
      date_first_observation, date_last_observation, sep = "/"
    )
  )
)
```

Show mapping:

```{r}
distribution %>%
  group_by(date_first_observation, date_last_observation, dwc_eventDate) %>%
  count()
```

### source

Inspect values:

```{r}
distribution %>%
  group_by(source) %>%
  count()
```

Map values:

```{r}
distribution %<>% mutate(dwc_source = source) 
```

### occurrenceRemarks

Inspect values:

```{r}
distribution %>%
  group_by(remarks) %>%
  count()
```

Map values:

```{r}
distribution %<>% mutate(dwc_occurrenceRemarks = remarks) 
```

## Post-processing

Only keep the Darwin Core columns:

```{r}
distribution %<>% select(starts_with("dwc_"))
```

Drop the `dwc_` prefix:

```{r}
colnames(distribution) <- str_replace(colnames(distribution), "dwc_", "")
```

Preview data:

```{r}
distribution %>% head()
```

Save to CSV:

```{r}
write_csv(distribution, here("data", "processed", "distribution.csv"), na = "")
```

# Species profile extension

## Pre-processing

Create a dataframe with all data:

```{r}
species_profile <- input_data
```

## Term mapping

Map the data to [Species Profile](http://rs.gbif.org/extension/gbif/1.0/speciesprofile.xml).

### taxonID

```{r}
species_profile %<>% mutate(dwc_taxonID = taxon_id)
```

Inspect `realm`:

```{r}
species_profile %>% 
  group_by(realm) %>% 
  count()
```

### isMarine

```{r}
species_profile %<>% mutate(dwc_isMarine = "FALSE")
```

### isTerrestrial

```{r}
species_profile %<>% mutate(dwc_isTerrestrial = "TRUE")
```

### isFreshwater

```{r}
species_profile %<>% mutate(dwc_isFreshwater = "FALSE")
```

## Post-processing

Only keep the Darwin Core columns:

```{r}
species_profile %<>% select(starts_with("dwc_"))
```

Drop the `dwc_` prefix:

```{r}
colnames(species_profile) <- str_replace(colnames(species_profile), "dwc_", "")
```

Preview data:

```{r}
species_profile %>% head()
```

Save to CSV:

```{r}
write_csv(species_profile, here("data", "processed", "species_profile.csv"), na = "")
```

